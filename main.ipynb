{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.myntra.com/dresses?f=Gender%3Amen%20women%2Cwomen&sort=popularity'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_info(li_element):\n",
    "    try:\n",
    "        wait = WebDriverWait(li_element, 10)\n",
    "\n",
    "        # Wait for the product meta info to load\n",
    "        product_meta_info = wait.until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"product-productMetaInfo\"))\n",
    "        )\n",
    "\n",
    "        product_id = li_element.get_attribute(\"id\")\n",
    "\n",
    "        product_name = li_element.find_element(By.CLASS_NAME, \"product-product\").text\n",
    "\n",
    "        brand = li_element.find_element(By.CLASS_NAME, \"product-brand\").text\n",
    "\n",
    "        try: \n",
    "            discounted_price = li_element.find_element(By.CLASS_NAME, \"product-discountedPrice\").text\n",
    "            price = li_element.find_element(By.CLASS_NAME, \"product-strike\").text\n",
    "\n",
    "        except:\n",
    "            discounted_price = \"NA\"\n",
    "            price = li_element.find_element(By.CLASS_NAME, \"product-price\").text\n",
    "\n",
    "        image_element = li_element.find_element(By.TAG_NAME, \"img\")\n",
    "\n",
    "        image_url = image_element.get_attribute(\"src\")\n",
    "\n",
    "        product_link = li_element.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "\n",
    "        return {\n",
    "            \"id\": product_id,\n",
    "            \"product_name\": product_name,\n",
    "            \"brand\": brand,\n",
    "            \"price\": price,\n",
    "            \"discounted_price\": discounted_price,\n",
    "            \"image_url\": image_url,\n",
    "            \"product_link\": product_link,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting product info from <li>: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Data saved to 'products.csv'\n"
     ]
    }
   ],
   "source": [
    "li_container = driver.find_element(By.CLASS_NAME, \"results-base\")\n",
    "\n",
    "li_elements = li_container.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "products = []\n",
    "count = 0\n",
    "\n",
    "for li in li_elements:\n",
    "    if count > 10:\n",
    "        break\n",
    "    \n",
    "    product = extract_product_info(li)\n",
    "    if product:\n",
    "        products.append(product)\n",
    "    count = count + 1\n",
    "\n",
    "print(count)\n",
    "df = pd.DataFrame(products)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('products.csv', index=False)\n",
    "print(\"Data saved to 'products.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews.csv saved successfully.\n",
      "ratings.csv saved successfully\n"
     ]
    }
   ],
   "source": [
    "#To Extract 5 comments from the products extracted.\n",
    "#Function to extract the comments from the product review pages\n",
    "\n",
    "def extract_comments(p_id, product_review_url):\n",
    "\n",
    "    try:\n",
    "        driver.implicitly_wait(1)\n",
    "        \n",
    "        rating_elements = driver.find_elements(By.CLASS_NAME, \"user-review-starRating\")\n",
    "\n",
    "        review_container = driver.find_element(By.CLASS_NAME, \"detailed-reviews-userReviewsContainer\")\n",
    "        reviews = review_container.find_elements(By.CLASS_NAME, \"user-review-reviewTextWrapper\")\n",
    "\n",
    "        date_elements = driver.find_elements(By.CLASS_NAME, \"user-review-left\")\n",
    "\n",
    "        for i in range(min(5, len(reviews))):\n",
    "            rating = rating_elements[i].text.strip() if i < len(rating_elements) else \"N/A\"\n",
    "            comment = reviews[i].text.strip()\n",
    "            date = date_elements[i].find_elements(By.TAG_NAME, \"span\")[1].text.strip()\n",
    "\n",
    "            review_data.append({\n",
    "                'product_id': p_id,\n",
    "                'cust_rating': rating,\n",
    "                'comment': comment,\n",
    "                'date': date\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping reviews for product ID {p_id}: {e}\")\n",
    "\n",
    "def extract_ratings(p_id, product_review_url):\n",
    "\n",
    "    try:\n",
    "        driver.implicitly_wait(5)\n",
    "        \n",
    "        avg_container = driver.find_element(By.CLASS_NAME, \"index-averageRating\")\n",
    "        avg_ratings =  avg_container.find_element(By.TAG_NAME, \"span\").text\n",
    "        \n",
    "\n",
    "        ratings_data.append({\n",
    "            \"product_id\": p_id,\n",
    "            \"avg\": avg_ratings\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping ratings for product ID {p_id}: {e}\")\n",
    "\n",
    "df = pd.read_csv('products.csv')\n",
    "\n",
    "ratings_data = []\n",
    "review_data = []\n",
    "review_url = 'https://www.myntra.com/reviews/'\n",
    "\n",
    "#Iterates through all the product_id in the stored csv file and creates a link form each product.\n",
    "p_ids = df['id']\n",
    "for p_id in p_ids:\n",
    "    product_review_url = review_url + str(p_id)\n",
    "    driver.get(product_review_url)\n",
    "    extract_comments(p_id, product_review_url)\n",
    "    extract_ratings(p_id, product_review_url)\n",
    "\n",
    "df_reviews = pd.DataFrame(review_data)\n",
    "df_reviews.to_csv('reviews.csv', index=False)\n",
    "print(\"reviews.csv saved successfully.\")\n",
    "\n",
    "df_ratings = pd.DataFrame(ratings_data)\n",
    "df_ratings.to_csv('ratings.csv', index=False)\n",
    "print(\"ratings.csv saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
